\section{Technical Solution}

\input{src/technical solution/alevel_standard.tex}

\subsection{Virtual Machine}

The main method and entry point for the virtual machine is responsible for initialising SDL2 (the graphics library) and the LION processor struct, as well as timing the CPU's execution. The first part of the code validates SDL2 is installed on the users computer, and that a binary file has been provided to the virtual machine, throwing respective errors should either condition not be met. Following this, the main loop runs constantly until the halt flag is set on the CPU. The loop provides four functions:

\begin{enumerate}
  \item \textbf{Times refresh rate}: The elapsed time for each cycle is calculated by subtracting the time at the end and start of each loop. The expected time to wait to achieve a 60Hz refresh rate is then calculated with \texttt{1000/FPS} and the program waits the difference between the two, ensuring CPU execution slows to the correct speed.
  \item \textbf{Batches CPU cycles}: Since the rendering code cannot keep up with the 40MHz clock speed requirement, and runs itself at 60Hz, multiple CPU cycles have to be executed per rendering cycle. Calculated by dividing the clock speed by refresh rate. \texttt{CLOCK\_SPEED/FPS}
  \item \textbf{Updates the display when VRAM is modified}: the \texttt{is\_buffered} flag on the LION struct is set when a write instruction updates the region of memory representing VRAM. This prevents the graphics code throttling execution since it is only updated when required. 
  \item \textbf{Decrements the delay timer}: each frame, the delay timer is decremented meaning programs can use the delay timer to maintain track of time.
\end{enumerate}

\begin{lstlisting}[language=C]
#include <stdio.h>
#include "lion.h"
#include "screen.h"

int main(int argc, char *argv[]) {
  if (SDL_init() != 0) {
    printf("error initialising SDL2\n");
    return -1;
  }

  if (argc < 2) {
    printf("Incorrect arguments: expected filename");
    return -1;
  }

  struct LION *lion = LION_init();
  lion->is_running = true;
  lion->is_buffered = true; 

  LION_read_file(lion, argv[1]);

  while (lion->is_running) {
    uint64_t start_time = SDL_GetPerformanceCounter();
    SDL_Event e;
    
    while (SDL_PollEvent(&e)) {
      switch (e.type) {
        case SDL_QUIT:
          lion->is_running = false;
          break;
      }
    }

    // batch cycle execution to execute at 40MHz with a refresh rate of 60Hz
    for (int i = 0; (i < CLOCK_SPEED/FPS) && lion->is_running; i++)
      LION_emulate_cycle(lion);

    // only update the display if instructions have modified VRAM 
    if (lion->is_buffered) {
      SDL_update(lion);
      lion->is_buffered = false;
    }

    // calculate the time elapsed executing CPU cycles and wait for the remaining time 
    // to ensure the refresh rate stays a constant 60Hz
    uint64_t end_time = SDL_GetPerformanceCounter();
    uint64_t elapsed_time = (end_time - start_time) / (float)SDL_GetPerformanceFrequency() * 1000.0f;
    SDL_Delay(floor((1000/FPS) - elapsed_time));

    // decrement the delay timer every frame
    if (lion->memory[DT] > 0) {
      lion->memory[DT] -= 1;
    }
  }

  SDL_close();

  return 0;
}
\end{lstlisting}

Below is the LION struct definition, and the two methods called during initalisation. The first prevents garbage values being preset into the memory or register arrays by initialising all values to 0, and the second reads a binary file one word at a time into the first \texttt{n} memory locations.

\label{LIONReadFile}
\begin{lstlisting}[language=C]
struct LION {
  uint16_t pc;   // store the address of the next instruction
  uint32_t cir;  // store the current instruction being executed
  uint16_t r[REG_NUM];
  uint16_t memory[RAM_SIZE];
  bool keypad[16];

  bool is_running;
  bool is_buffered; // determines when to update screen
};

struct LION *LION_init(void) {
  struct LION *lion = malloc(sizeof(struct LION));

  // initialise all RAM and Registers to 0, preventing indeterminate values
  for (int i = 0; i < RAM_SIZE; i++)
    lion->memory[i] = 0;

  for (int i = 0; i < REG_NUM; i++)
    lion->r[i] = 0;

  lion->pc = 0;
  return lion;
}

void LION_read_file(struct LION *lion, char *filename) {
  FILE *fileptr;
  long filesize;

  // get the length of file in bytes
  fileptr = fopen(filename, "rb");
  fseek(fileptr, 0, SEEK_END);

  filesize = ftell(fileptr);
  rewind(fileptr);

  // iterate through the file 2 bytes at a time, storing them together as a word in memory
  for (int address = 0; address < filesize/2; address++) {
    uint16_t word = 0;
    fread(&word, 1, 2, fileptr);
    lion->memory[address] = word;
  }

  fclose(fileptr);
}   
\end{lstlisting}

After the LION struct has been initialised, it is responsible for carrying out the cycle-by-cycle execution of the processosr. This is handled by two methods: \texttt{LION\_emulate\_cycle()} and \texttt{LION\_emulate\_instruction()}. The former reads an instruction in two parts from two addresses in from memory and logically combines them into a single 32-bit representation. It also increments the program counter before calling the second method which is responsible for executing that instruction. \texttt{LION\_emulate\_instruction()} initially decodes the instruction into any potential memory addresses, immediate values, or registers and switches on the opcode. Each possible instruction has its own branch which contains the code required to simulate its behaviour within the LION processor.

\begin{lstlisting}[language=C]
void LION_emulate_cycle(struct LION *lion) {
  // combine the two words into a 32 bit instruction
  lion->cir = (lion->memory[lion->pc+1] << 16) 
    | lion->memory[lion->pc];
  lion->pc += 2;    

  LION_emulate_instruction(lion);
}

void LION_emulate_instruction(struct LION *lion) {
  uint32_t opcode = lion->cir >> 28;

  // decode instruction into components 
  uint32_t rs = extract_bits(lion->cir, 5, 5);
  uint32_t rt = extract_bits(lion->cir, 10, 5);
  uint32_t rd = extract_bits(lion->cir, 15, 5);
  int16_t immediate = extract_bits(lion->cir, 15, 16);
  uint32_t func = extract_bits(lion->cir, 20, 4);

  switch (opcode) {
    case HLT:
      LION_display_registers(lion);
      lion->is_running = false;
      break;

    case R: // (func) $rd, $rs, $rt
      switch (func) {
        case FUNC_AND:
          lion->r[rd] = lion->r[rs] & lion->r[rt];
          break;

        case FUNC_OR:
          lion->r[rd] = lion->r[rs] | lion->r[rt];
          break;

        case FUNC_ADD:
          lion->r[rd] = lion->r[rs] + lion->r[rt];
          break;

        case FUNC_SUB:
          lion->r[rd] = lion->r[rs] - lion->r[rt];
          break;

        case FUNC_SLT:
          lion->r[rd] = (int16_t)lion->r[rs] <  (int16_t)lion->r[rt];
          break;

        case FUNC_NOR:
          lion->r[rd] = ~(lion->r[rs] | lion->r[rt]);
          break;
      }
      break;

    case ANDI: // andi $rt, $rs, i16
      lion->r[rt] = lion->r[rs] & immediate;
      break;

    case ORI : // ori $rt, $rs, i16
      lion->r[rt] = lion->r[rs] | immediate;
      break;

    case ADDI: // addi $rt, $rs, i16
      lion->r[rt] = lion->r[rs] + immediate;
      break;

    case SLTI: // addi $rt, $rs, i16
      lion->r[rt] = (int16_t)lion->r[rs] < (int16_t)immediate;
      break;

    case LW: // lw $rt, i16($rs)
      lion->r[rt] = lion->memory[lion->r[rs] + immediate];
      break;

    case SW: // sw $rt, i16($rs)
      lion->memory[lion->r[rs] + immediate] = lion->r[rt];

      // set is_buffered if accessing locations in VRAM
      if (lion->r[rs] + immediate >= 0x8000 && lion->r[rs] + immediate <= 0x8800)
        lion->is_buffered = true;
      break;

    case BEQ: // beq $rt, $rs, i16
      if (lion->r[rs] == lion->r[rt])
        lion->pc += immediate << 1;
      break;

    case BNE: // bne $rt, $rs, i16
      if (lion->r[rs] != lion->r[rt])
        lion->pc += immediate << 1;
      break;

    case JMP: // jmp i16
      lion->pc = immediate;
      break;

    case JAL: // jmp $rt, i16
      lion->r[rt] = lion->pc;
      lion->pc = immediate;
      break;

    case JR: // jmp $rs
      lion->pc = lion->r[rs];
      break;
  }
}
\end{lstlisting}

\subsection{Assembler}
The first step of the assembler (and compiler) is to tokenize the program string of characters into a series of data structures that can be processed easier by the parser. I've represented each token as an enum with a type and parameter. 

\begin{lstlisting}[language=C]
#[derive(Debug, PartialEq, Eq, Hash, Clone)]
pub enum Token {
  Number(u16),
  Label(String),
  Register(u16),

  EOF,
  NEWLINE,
  COMMA,

  LPAREN,
  RPAREN,
  LSQUARE,
  RSQUARE,

  BEQ,
  AND,
  XOR,
  \\[...]
  JAL,
  PUSH,
  POP,
}
\end{lstlisting}

In order to meet one of my objectives, my assembler and compiler both require pretty-printing of error messages. This means keeping track of the position of each and every token in source code. I created a generic \texttt{Span<T>} wrapper struct which takes in a generically typed parameter (and therefore can be reused both for lexer tokens and parser nodes). Each \texttt{Span} references a \texttt{Loc}, which itself stores the start position and length of a particular token. Since all source locations are stored as a one dimensional index, the \texttt{get\_pos()} function converts this into a line and column number, meaning errors can point to specific characters within the source code.

\begin{lstlisting}[language=C]
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub struct Loc {
  pub pos: usize,
  pub len: usize,
}

impl Loc {
  pub fn new(s_pos: usize, e_pos: usize) -> Self {
    Loc {
      pos: s_pos,
      len: e_pos - s_pos + 1,
    }
  }

  pub fn get_pos(&self, program: &str) -> Option<(usize, usize)> {
    let mut pos = self.pos;
    for (line_number, line) in program.lines().enumerate() {
      if pos <= line.len() + 1 {
        return Some((line_number, pos));
      }

      // + 1 accounts for newline characters not included in len()
      pos -= line.len() + 1;
    }

    None
  }
}

impl Add for Loc {
  type Output = Loc;

  fn add(self, rhs: Loc) -> Loc {
    Loc {
      pos: self.pos,
      len: rhs.pos + rhs.len - self.pos,
    }
  }
}

#[derive(Clone, PartialEq, Eq)]
pub struct Span<T> {
  pub v: T,
  pub loc: Loc
}

impl<T> Span<T> {
  pub fn new(t: T, s: Loc) -> Span<T> {
    Span {
      v: t,
      loc: s,
    }
  }
}

// helper functions to simplify memory management when 
// wrapping data types with the Span struct
impl<T: Copy> Copy for Span<T> {}

impl<T> Deref for Span<T> {
  type Target = T;
  fn deref(&self) -> &T {
    &self.v
  }
}

impl<T> DerefMut for Span<T> {
  fn deref_mut(&mut self) -> &mut T {
    &mut self.v
  }
}

impl<T: fmt::Debug> fmt::Debug for  Span<T> {
  fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
    write!(f, "{:?}", self.v)
  }
}
\end{lstlisting}

I have represented the source code as a linked list of characters inside the lexer, through which it can advance, peek and retreat. Whenever the lexer encounters a character, it enters a switch statement. Could the character form part of a longer, multicharacter spanning token (e.g. '+=' or '!=') - the next character in the source code will be viewed to determine whether to return a single character token, or advance another place in the source code and combine them. e.g. should a '+' be encountered, and the next character in the source is '=' they would be tokenised together as \texttt{ADD\_EQ} rather than \texttt{ADD}.

Should the lexer encounter an alphabetic character (\texttt{read\_identifier()}), it will continue scanning the source code while it encounters alphanumeric characters, appending each characeter to an identifier string. Once the string has been built up from all consecutive alphanumeric characters, the lexer will determine whether it is a label or mneumonic. Mneumonics are represented by their own tokens - wheras labels are all under the banner of a \texttt{LABEL} token.

Should a numerical character be encountered (\texttt{read\_number()}), the lexer will first determine whether a prefix such as '0x' or '0b' has been encountered. Once the lexer knows which base it expects the number to be in, it continues iterating whilst it encounters a valid digit, and multiplies the digit by its base and offset from the start, adding it to a running total that represents the base 10 of the tokenized number. 

\begin{lstlisting}[language=C]
pub struct Lexer<'a> {
  source: Chars<'a>,
  pos: usize,
  ch: char,
}

impl<'a> Lexer<'a> {
  pub fn new(mut source: Chars<'a>) -> Self {
    Self {
      ch: source.next().unwrap(),
      pos: 0,
      source,
    }
  }

  // advance the pointer through the source code, 
  // self.ch is set to a null byte at the end of the file
  pub fn eat(&mut self) -> char {
    self.pos += 1;
    self.ch = self.source.next().unwrap_or('\0');
    self.ch
  }

  // advance only if the next character is expected
  // used to lex multi-character tokens e.g. !, !=
  pub fn eat_if(&mut self, ch: char) -> bool {
    self.peek() == ch && { self.eat(); true }
  }

  // return a copy of the next character in the source code
  pub fn peek(&self) -> char {
    self.source.clone().next().unwrap_or('\0')
  }

  pub fn tokenize(source: Chars<'a>) -> Vec<Span<Token>> {
    let mut lexer = Lexer::new(source);
    let mut tokens: Vec<Span<Token>> = Vec::new();

    while lexer.ch != '\0' {
      let s_pos = lexer.pos;
      if let Some(token) = lexer.tokenize_char() {
        tokens.push(Span::new(token, Loc::new(s_pos, lexer.pos)));
      }
      lexer.eat();
    }

    // terminate lexer output with EOF token
    tokens.push(Span::new(
      Token::EOF,
      Loc::new(lexer.pos, lexer.pos)
    ));

    tokens
  }

  pub fn tokenize_char(&mut self) -> Option<Token> {
    match self.ch {
      '(' => Some(Token::LPAREN),
      ')' => Some(Token::RPAREN),
      '{' => Some(Token::LBRACE),
      '}' => Some(Token::RBRACE),
      ',' => Some(Token::COMMA),
      '^' => Some(Token::XOR),
      ':' => Some(Token::COLON),
      ';' => Some(Token::SEMICOLON),

      '+' => Some(
        if self.eat_if('+') { Token::INC } 
        else if self.eat_if('=') { Token::ADDEQ } 
        else { Token::PLUS }
      ),

      '=' => Some(if self.eat_if('=') { Token::EE } else { Token::EQ }),
      '<' => Some(if self.eat_if('=') { Token::LTE } else { Token::LT }),

      ch if ch.is_ascii_digit() => self.tokenize_number(),
      ch if ch.is_alphabetic() => self.tokenize_identifier(),
      ch if ch == '\'' => self.tokenize_char_literal(),

      ch if ch.is_whitespace() => None,

      _ => fatal_at!(
        format!("Syntax Error: unexpected character in lexer {:?}", self.ch),
        Loc::new(self.pos, self.pos)
      ),
    }
  }

  fn tokenize_char_literal(&mut self) -> Option<Token> {
    let ch = self.eat();
    if !self.ch.is_ascii() || self.peek() != '\'' {
      fatal_at!("Syntax Error: invalid character literal", Loc::new(self.pos - 1, self.pos - 1))
    }

    self.eat();
    Some(Token::Char(ch))
  }

  fn tokenize_identifier(&mut self) -> Option<Token> {
    let identifier = self.read_identifier();
    if let Some(tok) = Token::from_identifier(&identifier) {
      Some(tok)
    } else {
      Some(Token::Identifier(identifier))
    }
  }

  fn tokenize_number(&mut self) -> Option<Token> {
    // should the prefix 0x or 0b be encountered, parse the subsequent 
    // digit string into an integer with base 16, 2 or 10 respectively

    let number = match (self.ch, self.peek()) {
      ('0', 'x') => {
        self.eat();
        self.eat();
        self.read_number(16)
      },
      ('0', 'b') => {
        self.eat();
        self.eat();
        self.read_number(2)
      },
      _ => self.read_number(10)
    };

    Some(Token::Number(number))
  }
  
  fn read_number(&mut self, base: u32) -> u16 {
    let mut sum: u16 = self.ch.to_digit(base).unwrap_or_else(|| 
      fatal_at!(
        "Syntax Error: expected digit after base prefix", 
        Loc::new(self.pos, self.pos)
      )) as u16;

    // convert the next character into an integer provided it is a digit 
    // of the correct base and shift the previous total 1 place to the left 
    // (sum * base) and add the newly parsed digit 
    while let Some(n) = self.peek().to_digit(base) {
      sum = (sum * base as u16) + n as u16;
      self.eat();
    }

    sum
  }

  fn read_identifier(&mut self) -> String {
    let mut identifier = String::from(self.ch);
    while self.peek().is_alphanumeric() || self.peek() == '_' {
      self.eat();
      identifier += &self.ch.to_string(); 
    }

    identifier
  }
}
\end{lstlisting}

\subsubsection{Parser}
Once the source code has been tokenized, the parser needs to convert it into a series of data structures that can be easily compiled down into machine code. Each assembly program is composed of statements, a statement can be either a label declaration or an instruction. Each instruction can take one of two formats, I-format or R-format, each of which I have represented as an type in an Instruction enum.

\begin{lstlisting}[language=C]
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum Statement {
  Label(String),
  Instruction(Instruction),
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum Instruction {
  IFormat {
    mneumonic: Span<Token>,
    rs: Register,
    rt: Register,
    immediate: Span<Immediate>,
  },

  RFormat {
    mneumonic: Span<Token>,
    rs: Register,
    rt: Register,
    rd: Register,
  },
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Register(pub u16);

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum Immediate {
  Label(String),
  Number(u16),
}
\end{lstlisting}

The parser iterates through the tokens generated by the lexer, and depending on the mneumonic encountered, expects to find a different instruction format.

\begin{lstlisting}[language=C]
pub fn parse(&mut self) -> Result<Vec<Span<Statement>>, Exception> {
  let mut statements: Vec<Span<Statement>> = Vec::new();

  while *self.tok != Token::EOF {
    let statement : Span<Statement> = match &*self.tok {
      Token::Label(label) => {
        Span::new(
          Statement::Label(label.clone()),
          self.tok.loc,
        )
      }

      Token::ADD | Token::SUB => self.parse_rrr_format()?,
      Token::BEQ  | Token::BNE => self.parse_rri_format()?,
      Token::SW | Token::LW => self.parse_rir_format()?,

      _ => return Err(Exception::new(
        format!("Syntax Error: unexpected token encountered, expected LABEL or INSTRUCTION, got '{:?}'", *self.tok),
        self.tok.loc,
      ))
    };

    statements.push(statement);
    self.eat();
  }

  Ok(statements)
}
\end{lstlisting}

I write two functions to parse the different formats of operand, registers and immediates respectively. A register can optionally be encased in square brackets as is convention when addressing memory, however is handled the same regardless. An immediate can take two formats, either a 16 bit number, or a label contained within square brackets. The function switches based on whether it encounters a square bracket or number (throwing an unexpected operand exception otherwise) and parses each situtation seperately.

\begin{lstlisting}[language=C]
// [.label], n16
fn parse_immediate(&mut self) -> Result<Span<Immediate>, Exception> {
  self.eat();
  
  match *self.tok {
    Token::Number(n) => Ok(Span::new(
      Immediate::Number(n), 
      self.tok.loc
    )),

    Token::LSQUARE => {
      let label = self.eat_expect(
        Token::Label(String::new())
      )?.try_into().unwrap();

      self.eat_expect(Token::RSQUARE)?;
      Ok(label)
    }

    _ => Err(Exception::new(
      format!("Syntax Error: unexpected token, expected Number or '[Label]', got: '{:?}'", *self.tok),
      self.tok.loc
    ))
  }
}

// $rx, [$rx]
fn parse_register(&mut self) -> Result<Register, Exception> {
  self.eat();
  match *self.tok {
    Token::Register(reg) => Ok(Register(reg)),
    Token::LSQUARE => {
      let register = self.eat_expect(Token::Register(0))?
        .try_into().unwrap();

      self.eat_expect(Token::RSQUARE)?;
      Ok(register)
    }

    _ => Err(Exception::new(
      format!("Syntax Error: unexpected token, expected Register or '[Register]', got: '{:?}'", *self.tok),
      self.tok.loc
    ))
  }
} 
\end{lstlisting}

When a particular mneumonic is encountered in the top level of the parser, it looks up the corresponding instruction format and calls the corresponding function. Each parsing function uses the \texttt{parse\_register()} and \texttt{parse\_immediate()} functions to handle the operands. Should any expected tokens be missing (e.g. a comma), a syntax error is thrown by the \texttt{eat\_expect()} function. Finally, an Instruction Statement is outputted with a \texttt{Span} container that points to the start and end of the instruction in source code.

\label{AssemblerParseRRIFormat}
\begin{lstlisting}[language=C]
// addi $rt, $rs, [label] | immediate
fn parse_rri_format(&mut self) -> Result<Span<Statement>, Exception> {
  let mneumonic = self.tok.clone();

  let rt = self.parse_register()?;
  self.eat_expect(Token::COMMA)?;

  let rs = self.parse_register()?;
  self.eat_expect(Token::COMMA)?;

  let immediate = self.parse_immediate()?;

  Ok(Span::new(
    Statement::Instruction(Instruction::IFormat { 
      mneumonic: mneumonic.clone(), 
      rs, 
      rt, 
      immediate 
    }),
    self.tok.loc - mneumonic.loc
  ))
}
\end{lstlisting}

\subsubsection{Code Generation}
The compiler runs on a two-pass basis. The first pass is responsible for storing the numerical offsets for each label in the symbol table, and expanding macro instructions into one or more primative instructions. The second pass is responsible for translating the instruction objects into binary machine code. The first pass creates a vector to store all primative (expanded) machine code instructions. It then iterates through the parsed program, keeping an offset of the number of instruction encountered. When a label is encountered, a new entry in the Symbol table is created, mapping the label identfier to the instruction offset. This can be used in the second pass when calculating jump addresses. Should an instruction be countered, the \texttt{expand\_macro()} function is called. This function returns a list of expanded instructions that is appended to the \texttt{machine\_instructions()} vector. The \texttt{expand\_macro()} instruction first determines whether a mneumonic belongs to a primative or macro instruction. If it is a primative instruction, that instruction is returned alone. Else, it uses the template defining each macro instruction to determine the sequence of instructions to return.

\begin{lstlisting}[language=C]
fn first_pass(&mut self) -> Result<Vec<Span<Instruction>>, Exception> {
  let mut machine_instructions: Vec<Span<Instruction>> = Vec::new();

  let mut offset = 0;
  for stmt in self.statements.clone() {
    match &*stmt {
      // store offset to label in a symbol table
      Statement::Label(label) => {
        self.symbol_table.insert(label.clone(), offset);
      }

      Statement::Instruction(..) => {
        let mut expanded_macro = self.expand_macro(
          stmt.as_instruction().unwrap()
        )?;

        // increment instruction counter by the length of 
        // the expanded macro instruction

        offset += (expanded_macro.len() * 2) as u16;
        machine_instructions.append(&mut expanded_macro);
      }
    }
  }

  Ok(machine_instructions)
}
\end{lstlisting}

On the second pass of the compiler, the binary representation for each field in the machine code needs to be calculated. For a register, this is simply the register number (stored in the \texttt{.0} field on the register struct). For the opcode or func fields, these are properties of the mneumonic keyword token. And the immediate representation is calculated by the \texttt{compile\_immediate()} function, which determines whether the operand is a label or immediate value. Should it be a label, either a relative or absolute offset is calculated using the label and current instruction address.

\begin{lstlisting}[language=C]
pub fn compile_instruction(&mut self, instr: Span<Instruction>) -> Result<u32, Exception> {
  match &*instr {
    Instruction::IFormat {
      mneumonic,
      rs,
      rt,
      immediate,
    } => {
      let opcode = mneumonic.get_opcode()?;
      let rs = rs.0 as u32;
      let rt = rt.0 as u32;
      let immediate = self.compile_immediate(
        &immediate,
        // set the is_offset flag for B operations
        **mneumonic == Token::BEQ || **mneumonic == Token::BNE,
      )?;

      // combine fields into instruction
      Ok(((opcode) << 28) | (rs << 23) | (rt << 18) 
        | (immediate << 2))
    }

    Instruction::RFormat {
      mneumonic,
      rs,
      rt,
      rd,
    } => {
      let opcode = mneumonic.get_opcode()?;
      let func = mneumonic.get_func()?;
      let rs = rs.0 as u32;
      let rt = rt.0 as u32;
      let rd = rd.0 as u32;

      // combine fields into instruction
      Ok(((opcode) << 28) | (rs << 23) | (rt << 18) 
        | (rd << 13) | (func << 9))
    }
  }
}

pub fn compile_immediate(
  &self,
  immediate: &Span<Immediate>,
  as_offset: bool,
) -> Result<u32, Exception> {
  match &**immediate {
    Immediate::Label(label) => {
      // lookup label in symbol table
      if let Some(address) = self.symbol_table.get(&*label.clone()) {
        // if offset, calc relative distance from label 
        // to the current instruction, else return the address itself
        Ok(if as_offset {
          ((*address - self.word) / 2 - 1) as u32
        } else {
          *address as u32
        })
      } else {
        Err(Exception::new(
          format!("Syntax Error: undefined label {:?}", *label),
          immediate.loc,
        ))
      }
    }

    Immediate::Number(number) => Ok(*number as u32),
  }
}
\end{lstlisting}

\subsection{Compiler}
\subsubsection{Parser}
Once the source code has been tokenised by the lexer (which can be reused from the assembler), the tokens need to be parsed into an abstract syntax tree following the grammar rules defined in the parser specification in the design section. I encapsulated the parser code in a struct, containing the list of tokens, current token, current position and current scope. The current scope is unique for each Block the parser parses, and is used to reference a particular block scope in the Scope Table. 


\begin{lstlisting}[language=C]
pub struct Parser {
  tokens: Vec<Span<Token>>,
  tok: Span<Token>,
  pos: usize,
  scope: u32,
}

impl Parser {
  pub fn new(tokens: Vec<Span<Token>>) -> Self {
    Self {
      tok: tokens.get(0).unwrap().clone(),
      tokens: tokens,
      pos: 0,
      scope: 0,
    }
  }

  pub fn parse(tokens: Vec<Span<Token>>) -> Vec<Span<SYMBOL>> {
    let mut parser = Parser::new(tokens);
    let mut source = vec![];

    while *parser.tok != Token::EOF {
      source.push(parser.parse_symbol());
    }

    source
  }
}  
\end{lstlisting}

The parser outputs an Abstrat Syntax Tree composed of nodes, each node representing a program element. The formal grammar that dictates the nodes was designed in the Design section of the pratt parser.

\label{AST}
\begin{lstlisting}[language=C]
#[derive(Debug, Clone, Eq, PartialEq)]
pub enum SYMBOL {
  Const {
    binding: Span<Binding>,
    expr: Box<Span<EXPRESSION>>,
  },

  Function {
    ident: Span<Identifier>,
    bindings: Vec<Span<Binding>>,
    ret_ty: TYPE,
    body: Box<Span<Block>>, 
  }
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum STATEMENT {
  Declaration {
    binding: Span<Binding>,
    expr: Box<Span<EXPRESSION>>,
  },
  
  If {
    cond: Box<Span<EXPRESSION>>,
    conseq: Box<Span<Block>>,
    altern: Option<Box<Span<Block>>>
  },

  While {
    cond: Box<Span<EXPRESSION>>,
    body: Box<Span<Block>>,
  },

  For {
    init: Box<Span<STATEMENT>>,
    cond: Box<Span<EXPRESSION>>,
    inc: Box<Span<EXPRESSION>>,
    body: Box<Span<Block>>,
  },
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum EXPRESSION {
  Literal { lit: Span<LITERAL> },

  Call {
    func: Box<Span<EXPRESSION>>,
    args: Vec<Span<EXPRESSION>>,
  },

  Infix {
    lhs: Box<Span<EXPRESSION>>,
    op: BINOP,
    rhs: Box<Span<EXPRESSION>>,
  }, 

  Prefix {
    op: UNOP,
    rhs: Box<Span<EXPRESSION>>
  },
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum LITERAL {
  Int(u16),
  Char(char),
  Bool(bool),
}

impl LITERAL {
  // resolve the numerical value of the literal 
  pub fn unwrap(&self) -> u16 {
    match self {
      LITERAL::Char(ch) => *ch as u16,
      LITERAL::Bool(b) => *b as u16,
      LITERAL::Int(n) => *n,
    }
  }

  // resolve the data type of the Literal
  pub fn ty(&self) -> TYPE {
    match self {
      LITERAL::Char(_) => TYPE::CHAR,
      LITERAL::Bool(_) => TYPE::BOOL,
      LITERAL::Int(_) => TYPE::INT,
    }
  }
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Block {
  pub stmts: Vec<Span<STATEMENT>>,

  // reference to block scope in the Scope Table
  pub scope: ScopeId, 
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Binding {
  pub ident: Span<Identifier>,
  pub ty: TYPE,
} 
\end{lstlisting}

There are two functions to help iterate through the source tokens, an \texttt{eat()} function and an \texttt{assert()}. The eat function advances one token, setting the values of the \texttt{self.tok} and \texttt{self.pos} fields. The assert function takes an expected token as a parameter and throws a syntax error if the current token is not the same.

\begin{lstlisting}[language=C]
pub fn eat(&mut self) {
  if self.pos + 1 < self.tokens.len() {
    self.pos += 1;
    self.tok = self.tokens.get(self.pos).unwrap().clone();
  }
}

pub fn assert(&mut self, expect: Token) {
  if *self.tok != expect {
    fatal_at!(
      format!("Syntax Error: expected {:?}, got {:?}", expect, *self.tok),
      self.tok.loc
    )
  }
}
\end{lstlisting}

For each iteration of the \texttt{parse()} loop, the \texttt{parse\_symbol()} function is called, generating a node in the Abstract Syntax Tree which is appended to the \texttt{source} vector. The \texttt{parse\_symbol()} function throws an error if the statement is neither a function declaration or constant, otherwise calls their respective parsing functions.

\begin{lstlisting}[language=C]
fn parse_symbol(&mut self) -> Span<SYMBOL> {
  match *self.tok {
    Token::FN => self.parse_fn(),
    Token::CONST => self.parse_const(),
    _ => fatal_at!(
      format!(
        "Syntax Error: expected 'fn' or 'const', got {:?}",
        *self.tok
      ),
      self.tok.loc
    ),
  }
}
\end{lstlisting}

When parsing the parameters of a function, I created a vector to hold the parameter bindings. After the parser encounters a '(', it continues to parse bindings while it encounters a comma, breaking once the ')' character has been reached.

\label{CompilerParseSymbol}
\begin{lstlisting}[language=C]
// FN <ident> LPAREN (<ident>: <type>)* RPAREN (-> <type>)? <block> 
fn parse_fn(&mut self) -> Span<SYMBOL> {
  let s_pos = self.tok.loc;

  self.eat();
  let ident = self.parse_identifier();

  self.assert(Token::LPAREN);
  self.eat();

  let mut bindings: Vec<Span<Binding>> = Vec::new();
  while *self.tok != Token::RPAREN {
    bindings.push(self.parse_binding());

    if *self.tok != Token::COMMA {
      break;
    }

    self.eat();
  }

  self.eat();

  // if a '->' token follows the parameters, parse the return type,
  // else default to a VOID type
  let ret_ty = if *self.tok == Token::ARROW {
    self.eat();
    self.parse_type()
  } else {
    TYPE::VOID
  };

  let body = self.parse_block();

  Span::new(
    SYMBOL::Function {
      ident,
      bindings,
      ret_ty,
      body: Box::new(body),
    },
    s_pos + self.tok.loc,
  )
}

// CONST <ident>: <type> = <expr>;
fn parse_const(&mut self) -> Span<SYMBOL> {
  let s_pos = self.tok.loc;

  self.eat();

  let binding = self.parse_binding();
  self.assert(Token::EQ);
  self.eat();

  let expr = self.parse_expression();
  self.assert(Token::SEMICOLON);
  self.eat();

  Span::new(
    SYMBOL::Const {
      binding: binding,
      expr: Box::new(expr),
    },
    s_pos + self.tok.loc,
  )
}
\end{lstlisting}

A block consists of a sequence of semi colon terminated satements contained between two curly braces. 

\begin{lstlisting}[language=C]
fn parse_block(&mut self) -> Span<Block> {
  let s_pos = self.tok.loc;
  self.assert(Token::LBRACE);
  self.eat();

  let mut stmts: Vec<Span<STATEMENT>> = Vec::new();
  while *self.tok != Token::RBRACE {
    stmts.push(self.parse_statement());
  }

  self.eat();

  // assign a unique scope to the block at creation
  Span::new(
    Block { 
      stmts, 
      scope: self.next_scope() 
    }, 
    s_pos + self.tok.loc
  )
}
\end{lstlisting}

When entering the \texttt{parse\_statement()} function, use the keyword token to determine how to parse the subsequence tokens. Should a statement have no keyword preceeding it, it is parsed as an expression terminated by a semi colon. 

\begin{lstlisting}[language=C]
fn parse_statement(&mut self) -> Span<STATEMENT> {
  match *self.tok {
    Token::LET => self.parse_declaration(),
    Token::RETURN => self.parse_return(),
    Token::IF => self.parse_if(),
    Token::WHILE => self.parse_while(),
    Token::FOR => self.parse_for(),

    _ => {
      let expr = self.parse_expression();
      self.assert(Token::SEMICOLON);
      self.eat();
      Span::new(
        STATEMENT::Expression {
          expr: Box::new(expr.clone()),
        },
        expr.loc,
      )
    }
  }
}

// while <expression> <block> 
fn parse_while(&mut self) -> Span<STATEMENT> {
  let s_pos = self.tok.loc;
  self.eat();
  let cond = self.parse_expression();
  let body = self.parse_block();

  Span::new(
    STATEMENT::While { 
      cond: Box::new(cond), 
      body: Box::new(body) 
    },
    s_pos + self.tok.loc
  )
}

// if <condition> <block> (else (<block> | <if>))?
fn parse_if(&mut self) -> Span<STATEMENT> {
  let s_pos = self.tok.loc;

  self.eat();
  let cond = self.parse_expression();
  let conseq = self.parse_block();
  let mut altern = None;

  // parse alternative if an else block exists
  // else set altern to None 
  if *self.tok == Token::ELSE {
    self.eat();
    // if ELSE IF, then recursively parse the if block as the 
    // alternative attribute, otherwise parse a block 
    if *self.tok == Token::IF {
      altern = Some(Box::new(
        Span::new(Block {
          stmts: vec![self.parse_if()],
          scope: self.next_scope(),
        }, s_pos + self.tok.loc)
      ));

      self.scope += 1;
    } else {
      altern = Some(Box::new(self.parse_block()));
    }
  }

  Span::new(
      STATEMENT::If { 
        cond: Box::new(cond), 
        conseq: Box::new(conseq), 
        altern 
      },
      s_pos + self.tok.loc
  )
}
\end{lstlisting}

The \texttt{parse\_expression()} handles expressions ranging from arithmetic operations to variable assignments. It parses the left hand side of any operation as a full pratt expression, meaning statements like \texttt{\&(vram + 0x0b) = 10} can be represented with arithmetic operations on the left hand side of an assignment. It then determines whether the folowing token is an '\texttt{=}' or increment operation such as '\texttt{+=}', if it encounters one of the two, it is an assignment operation and handled by the \texttt{parse\_assign()} function, else it simply returns the expression itself. The \texttt{parse\_assign()} function simply parses the right hand side as another pratt expression and returns the result in an \texttt{EXPRESSION::Assign} enum variant. 

\begin{lstlisting}[language=C]
fn parse_expression(&mut self) -> Span<EXPRESSION> {
  let expr = match *self.tok {
    _ => self.parse_pratt(0),
  };

  match &*self.tok {
    Token::EQ => self.parse_assign(expr),
    tok if BINOP::from_assign_op(tok.clone()).is_some() => self.parse_assign_op(expr),
    _ => expr,
  }
}

fn parse_assign(&mut self, lhs: Span<EXPRESSION>) -> Span<EXPRESSION> {
  let s_pos = self.tok.loc;
  self.eat();
  let rhs = self.parse_expression();

  Span::new(
    EXPRESSION::Assign { 
      lhs: Box::new(lhs), 
      rhs: Box::new(rhs) 
    }, 
    s_pos + self.tok.loc
  )
}
\end{lstlisting}

\subsubsubsection{Pratt Parser}
Below is the impelmentation of the Pratt parsing algorithm designed in the previous section. I extrapolated the prefix code into the \texttt{parse\_atom()} function. 

\label{PrattParser}
\begin{lstlisting}[language=C]
fn parse_pratt(&mut self, rbp: i32) -> Span<EXPRESSION> {
  let s_pos = self.tok.loc;

  // parse LHS, including prefixes (parenthesis, literals)
  // e.g. ++x, (10+2), &x
  let mut lhs = self.parse_atom();


  // parse all postfix operations for the LHS
  // f(), a[], x++
  while let Some(op) = POSTOP::from((*self.tok).clone()) {
    self.eat();
    lhs = Span::new(
      EXPRESSION::Postfix { lhs: Box::new(lhs), op },
      s_pos + self.tok.loc,
    );
  }

  // continue parsing into the RHS of the expression while 
  // binary operations of a higher precedence are encountered
  while let Some(op) = BINOP::from((*self.tok).clone()) {
    if op.get_precedence() < rbp {
      break;
    }

    self.eat();
    let rhs = self.parse_pratt(op.get_precedence() + 1);

    // set LHS to newly parsed expression so it can be built
    // off of each iteration 
    lhs = Span::new(
      EXPRESSION::Infix {
        lhs: Box::new(lhs),
        op: op,
        rhs: Box::new(rhs),
      },
      s_pos + self.tok.loc,
    );
  }

  lhs
}
\end{lstlisting}

The \texttt{parse\_atom()} function handles parenthesis that contain a regular pratt expression. Implementing this as an atom allows the order of operations to be followed since whatever is contained within the brackets will be evaluated before any superceeding operations. It also handles unary operations that come before an expression, e.g. (\texttt{-10}, \texttt{\&x}). Each prefix operation is given a binding precedence, and this binding precedence is used as the base precedence for the \texttt{parse\_pratt\_expression()} call, preventing \texttt{*x - 4} being parsed as \texttt{DEREF(x - 4)} instead of \texttt{DEREF(x) - 4}. 

\begin{lstlisting}[language=C]
fn parse_atom(&mut self) -> Span<EXPRESSION> {
  let s_pos = self.tok.loc;

  let expr = match &*self.tok.clone() {
    Token::LPAREN => {
      self.eat();
      let expr = self.parse_expression();
      self.assert(Token::RPAREN);
      self.eat();
      expr
    }

    tok if UNOP::from(tok.clone()).is_some() => {
      let prefix = UNOP::from((*self.tok).clone()).unwrap();
      self.eat();
      let rhs = self.parse_pratt(prefix.get_precedence());

      Span::new(
        EXPRESSION::Prefix { 
          op: prefix, 
          rhs: Box::new(rhs) 
          }, 
          s_pos + self.tok.loc
       )
    }

    _=> self.parse_literal(),
  };

  // if '(' after atom, parse as a function call
  match *self.tok {
    Token::LPAREN => self.parse_call(expr),
    _ => expr
  }
}
\end{lstlisting}

The most fundemental unit of the abstract syntax tree is the program literal. Each one corresponds to a single token therefore all the \texttt{parse\_literal()} function has to do is map the token to its corresponding expression literal. 

\begin{lstlisting}[language=C]
fn parse_literal(&mut self) -> Span<EXPRESSION> {
  let s_pos = self.tok.loc;
  let expr = match &*self.tok {
    Token::Number(n) => EXPRESSION::Literal { 
      lit: Span::new(LITERAL::Int(*n), 
      self.tok.loc) 
    },

    Token::Char(ch) => EXPRESSION::Literal { 
      lit: Span::new(LITERAL::Char(*ch), 
      self.tok.loc) 
    },

    Token::TRUE => EXPRESSION::Literal { 
      lit: Span::new(LITERAL::Bool(true), self.tok.loc) 
    },

    // [...]

    _ => fatal_at!(
      format!(
        "Syntax Error: expected program literal, got {:?}",
        *self.tok
      ),
      self.tok.loc
    ),
  };

  self.eat();
  Span::new(expr, s_pos)
}
\end{lstlisting}

Finally, the last component when parsing a program is to handle the function calls. They are composed of an identifier, followed by  '(' with 0 or more arguments and a terminating ')'. The arguments consist of a series of expressions seperated by a comma.  Iteratively parsing expressions whilst a comma is encountered, and storing the result in a vector is sufficient to collect the arguments which are passed as an attribute into the \texttt{EXPRESSION::Call} variant. 

\begin{lstlisting}[language=C]
fn parse_call(&mut self, func: Span<EXPRESSION>) -> Span<EXPRESSION> {
  let s_pos = self.tok.loc;

  self.assert(Token::LPAREN);
  self.eat();

  // continue collecting arguments while a ',' is encountered 
  // and before the terminating ')' 
  let mut args: Vec<Span<EXPRESSION>> = Vec::new();
  while *self.tok != Token::RPAREN {
    args.push(self.parse_expression());

    if *self.tok != Token::COMMA {
      break;
    }

    self.eat();
  }

  self.eat();
  Span::new(EXPRESSION::Call { 
    func: Box::new(func), 
    args: args 
  }, s_pos + self.tok.loc)
}
\end{lstlisting}

\subsubsection{Optimisations and Sentiment Analysis}
\subsubsubsection{AST Traveral}
The optimisations require the ability to traverse every node in the abstract syntax tree. I created a trait to implement a depth first search traversal that could be itself implemented by the optimisation structs. The \texttt{Walker} trait contains \texttt{walk()} functions that recursively iterate over all child nodes for a particular node in the abstract syntax tree, and call abstract \texttt{visit()} methods that are themselves overwritten in the optimisation code to handle that particular node. The \texttt{walk()} method is called on the root node of the AST, and the Walker trait recursively visits each child node, calling the corresponding \texttt{visit()} method for each. 

\label{Walker}
\begin{lstlisting}[language=C]
pub trait Walker {

fn walk(&mut self, ast: &mut Vec<Span<SYMBOL>>) {
  for sym in ast {
    self.visit_symbol(sym);
  }
}

fn walk_symbol(&mut self, symbol: &mut Span<SYMBOL>) {
    match &mut **symbol {
      SYMBOL::Const { binding, expr } => {
        self.visit_binding(binding);
        self.visit_expression(&mut **expr);
      }, 

      SYMBOL::Function { ident, bindings, ret_ty, body } => {
        self.visit_identifier(&mut *ident);
        for binding in bindings {
          self.visit_binding(&mut *binding);
        }

        self.visit_type(&mut *ret_ty);
        self.visit_block(body);
      }
  } 
}

fn walk_block(&mut self, block: &mut Span<Block>) {
  for stmt in &mut block.stmts {
    self.visit_statement(stmt);
  }
}

//[...]
}
\end{lstlisting}

\subsubsubsection{Const Folding}
The first optimisation my compiler performs involves pre calculating the result of expressions and storing the result as a node in place of the infix node. The walker visits each node in the abstract syntax tree. If it encounters an infix node, it recursively calls the \texttt{fold\_constant()} function on the left and right hand side of the expression. The fold constants function checks if the lhs and rhs have been evaluated as constants, if they have - it performs the calculation and stores the result in a Literal node. 

\begin{lstlisting}[language=C]
pub struct ConstFolding;
impl ConstFolding {

pub fn run(ast: &mut Vec<Span<SYMBOL>>) {
  let mut cf = ConstFolding;
  cf.walk(ast);
}

fn fold_constant(&mut self, e: &Span<EXPRESSION>) 
  -> Option<Span<EXPRESSION>> {
  match &**e {
    EXPRESSION::Literal { .. } => return Some(e.clone()),

    // recursively fold the lhs and rhs of an expression 
    // if both fold to constants, combine them and
    // replace the current node
    EXPRESSION::Infix { lhs, op, rhs } => {
      if let (
        Some(EXPRESSION::Literal { lit: lhs }), 
        Some(EXPRESSION::Literal { lit: rhs })) 
      = (self.fold_constant(lhs), self.fold_constant(rhs)) {
        let result = match op {
          BINOP::ADD => Some(LITERAL::Int(lhs + rhs)),
          BINOP::MUL => Some(LITERAL::Int(lhs * rhs)),
          BINOP::DIV => Some(LITERAL::Int(lhs / rhs)),
          BINOP::OR  => Some(LITERAL::Int(lhs | rhs)),
          BINOP::XOR => Some(LITERAL::Int(lhs ^ rhs)),
          BINOP::AND => Some(LITERAL::Int(lhs & rhs)),
          _ => None,
        };

        // return the folded literal node
        if let Some(lit) = result {
          return Some(Span::new(
            EXPRESSION::Literal { 
              lit: Span::new(lit, e.loc) 
            }, e.loc
          ))
        }
      } else {
        return self.fold_constant(lhs)
      }
    },

    _ => {},
  }

  None
} 
}

// Walker visits each node in the AST, visit_expression() 
// is called on each infix node to fold the lhs and rhs
impl Walker for ConstFolding {
  fn visit_expression(&mut self, e: &mut Span<crate::ast::EXPRESSION>) {
    if let Some(lit) = self.fold_constant(e) {
      *e = lit;
    } else {
      self.walk_expression(e);
    }
  }
}
\end{lstlisting}

\subsubsubsection{Type Checking}
The type checker visits every node in the AST and uses the \texttt{resolve()} function to determine what data type the child nodes evaluate into. This process uses the symbol table (a HashMap containing all the variables, constants, and function declarations accessible within a particular scope) to resolve the type of variables. For an infix expression, \texttt{resolve()} is called twice, for the lhs and rhs respectively, and their types are compared to determine compatability.  

\begin{lstlisting}[language=C]
pub struct Typeck<'a> {
  // a reference to the symbol table generated after parsing
  symtbl: &'a mut SymbolTable,

  // contains the current scope from which to resolve variables
  scope: Option<ScopeId>,
}

impl<'a> Typeck<'a> {
  fn new(symtbl: &'a mut SymbolTable) -> Self {
    Self {
      symtbl: symtbl,
      scope: None,
    }
  }

  pub fn run(ast: &mut Vec<Span<SYMBOL>>, symtbl: &'a mut SymbolTable) {
    let mut typeck = Typeck::new(symtbl);
    typeck.walk(ast);
  } 
}

impl<'a> Walker for Typeck<'a> {
  fn visit_symbol(&mut self, s: &mut Span<SYMBOL>) {
    match &**s {
      SYMBOL::Function {
        ret_ty,
        body,
        ..
      } => {
        self.resolve_block(body, Some(&ret_ty));
      }

      SYMBOL::Const { binding, expr } => {
        self.resolve_expression(expr, Some(&binding.ty));
      }
    };
  }
}
\end{lstlisting}

The following function is called to determine whether an encountered type is of the expected type.

\begin{lstlisting}[language=C]
fn verify(&self, got: &TYPE, expected: Option<&TYPE>, loc: Loc) -> TYPE {
  if let Some(expected) = expected {
    if got != expected {
      fatal_at!(
        format!(
          "Linking Error: expected type '{}', got '{}'", 
          expected, got
        ),
        loc
      );
    }
  }

  got.clone()
} 
\end{lstlisting}

\begin{lstlisting}[language=C]
fn resolve_statement(
  &mut self, 
  stmt: &Span<STATEMENT>, 
  expected: Option<&TYPE>) -> TYPE {

  let got = match &**stmt {

    // validate that the expression evaluates to 
    // the binding type, return VOID since declarations 
    // do not return a value
    STATEMENT::Declaration { binding, expr } => {
      self.resolve_expression(&**expr, Some(&binding.ty));
      TYPE::VOID
    },

    STATEMENT::If {
      cond,
      conseq,
      altern,
    } => {
      // ensure the condition evaluates to a boolean
      self.resolve_expression(cond, Some(&TYPE::BOOL));
      let conseq_ty = self.resolve_block(&**conseq, None);

      // ensure the if-then and else branches evaluate 
      // to the same type
      if let Some(altern) = altern {
        let altern_ty = self.resolve_block(&**altern, expected);

        if altern_ty != conseq_ty {
          fatal_at!(
            format!("Linking Error: mismatched types")
            stmt.loc
          );
        }
      }

      conseq_ty
    }
  };

  self.verify(&got, expected, stmt.loc)
}
\end{lstlisting}

\begin{lstlisting}[language=C]
fn resolve_block(
  &mut self, 
  block: &Span<Block>, 
  expected: Option<&TYPE>) -> TYPE {

  // set current scope to the block scope
  self.scope = Some(block.scope.clone());
  let mut ret_ty: Option<TYPE> = None;

  for stmt in &block.stmts {
    let stmt_ty = self.resolve_statement(&stmt, None);

    // the only statement that doesn't return VOID is return 
    // verify the return statement if of the correct type 
    // and store as the return type for the block
    if stmt_ty != TYPE::VOID {
      self.verify(&stmt_ty, expected, stmt.loc);
      ret_ty = Some(stmt_ty);
    }
  }

  // now block has been evaluated, return to parent scope
  self.scope = self.symtbl.parent_scope(self.scope.unwrap());

  match ret_ty {
    Some(ty) => ty,
    _ => TYPE::VOID,
  }
}
\end{lstlisting}

\begin{lstlisting}[language=C]
fn resolve_expression(
  &mut self, 
  expr: &Span<EXPRESSION>, 
  expected: Option<&TYPE>) -> TYPE {

  let got = match &**expr {
    // base case for recursive expression
    EXPRESSION::Literal { lit } => lit.ty(),

    EXPRESSION::Infix { lhs, rhs , op} 
      => self.resolve_infix(lhs, op, rhs),

    // [...]

    EXPRESSION::Assign { lhs, rhs } => {
      // ensure rhs and lhs are of the same type
      let lhs_ty = self.resolve_expression(lhs, None);
      self.resolve_expression(rhs, Some(&lhs_ty));
      TYPE::VOID
    }

    // lookup the variable in the current scope 
    EXPRESSION::Variable { ident } => self
      .symtbl
      .resolve_variable(self.scope, ident)
      .expect("could not resolve variable").ty
  };

  self.verify(&got, expected, expr.loc)
}
\end{lstlisting}

\begin{lstlisting}[language=C]
fn resolve_call(
  &mut self,
  func: &Span<EXPRESSION>,
  args: &Vec<Span<EXPRESSION>>,
  loc: Loc,
) -> TYPE {

  // ensure a valid function call
  let ident = if let EXPRESSION::Variable { ident } = &**func {
    ident
  } else {
    fatal!("Linking Error: attempt to call non-identifier");
  };

  let (bindings, ret_ty) = self.symtbl.resolve_fn(ident).unwrap();

  // ensure f() is called with the correct number of arguments
  if args.len() != bindings.len() {
    fatal_at!(
      format!("Linking Error: mismatched argument count [...]", 
      args.len()), 
    loc)
  }

  // iterate over corresponding pairs of parameters 
  // and argsuments, ensuring they are of the same type
  for (arg, binding) in args.iter().zip(bindings.into_iter()) {
    self.resolve_expression(arg, Some(&binding.ty));
  }

  ret_ty
}
\end{lstlisting}

\begin{lstlisting}[language=C]
fn resolve_infix(
  &mut self,
  lhs: &Span<EXPRESSION>,
  op: &BINOP,
  rhs: &Span<EXPRESSION>,
) -> TYPE {
  let lhs_ty = self.resolve_expression(lhs, None);
  let rhs_ty = self.resolve_expression(rhs, None);

  match op {
    BINOP::ADD | BINOP::SUB  => { 
      // verify the LHS and RHS are of compatible types 
      // e.g. an int can be added to a pointer 
      self.verify_compatible(
        &rhs_ty, 
        vec![
          &TYPE::INT, &TYPE::CHAR, 
          &TYPE::PTR(Box::new(TYPE::INT)), 
          &TYPE::PTR(Box::new(TYPE::CHAR)) 
        ], 
        rhs.loc
      );

      //[verify rhs]
    } ,


    BINOP::LT | BINOP::LTE | BINOP::GT  | 
    BINOP::GTE | BINOP::EE | BINOP::NE  => { 
      self.verify_compatible(
        &lhs_ty, 
        vec![&TYPE::INT, &TYPE::CHAR], 
        lhs.loc
      );

      // [verify rhs]

      // comparative operations return a bool regardless 
      // of their input types
      TYPE::BOOL
    } ,

    // ensure the lhs and rhs are both bools
    BINOP::LAND | BINOP::LOR => 
      self.verify(&lhs_ty, Some(&TYPE::BOOL), lhs.loc)
  }
}
\end{lstlisting}

\begin{lstlisting}[language=C]
fn resolve_prefix(
  &mut self, 
  op: &UNOP, 
  rhs: &Span<EXPRESSION>
) -> TYPE {
  match op {
    // resolve the type of the expression within the ptr 
    // create a ptr to that type, can be defined recursively
    UNOP::PTR => TYPE::PTR(
      Box::new(self.resolve_expression(rhs, None))
    ),

    UNOP::DEREF => {
      // only pointers can be derefed, else throw an error
      let ty = self.resolve_expression(rhs, None);
      if let TYPE::PTR(ty) = ty {
        *ty
      } else {
        fatal_at!(
            format!("Cannot dereference '{}'", ty),
            rhs.loc
        );
      }
    }
  }
} 
\end{lstlisting}

\subsubsubsection{Scope Table Builder}
The scope table contains the local scope for each Block expression contained within the program. Each scope is referenced by a unique \texttt{ScopeId}, and contains a \texttt{HashMap} mapping identifiers to variable bindings which can be used to resolve the data type or stack slot of a particular variable. 

\begin{lstlisting}[language=C]
#[derive(Debug, Clone)]
pub struct SymbolTable {
  // symbols refer to constants and functions 
  symbols: HashMap<Identifier, SYMBOL>,

  // local variables (stack assigned) are stored in scopes
  scopes: HashMap<ScopeId, Scope>
}

#[derive(Debug, Clone)]
pub struct Scope {
  pub variables: HashMap<Identifier, Variable>,
  pub parent: Option<ScopeId>,
}

#[derive(Debug, Clone)]
pub struct Variable {
  pub ty: TYPE,
  // offset from stack's base pointer in the stack frame
  pub stack_slot: Option<i16>,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Copy)]
pub struct ScopeId(pub u32);
\end{lstlisting}

The \texttt{ScopeTableBuilder} iterates over each node in the program, when it enters a block, it first determines whether the block is a function scope or a block scope (function scopes have no parent scope). If it is a function scope, it registers a function scope in the SymbolTable, unique from a block scope since it correpsonds to a unique stack frame when the code is compiled. It sets the current scope of the \texttt{SymbolTableBuilder} to the Block's local scope, and recursively resolves all statemetns contained within.

\begin{lstlisting}[language=C]
fn visit_block(&mut self, b: &mut Span<Block>) {
  // create new Scope with curr Scope ID in Symbol Table
  self.symtbl.register_scope(&b.scope); 

  // since functions have no parent scope, if this block has 
  // no parent scope, define a new function scope, otherwise 
  // block exists within a function (e.g. for or while)
  if let Some(parent) = &self.scope {
    self.symtbl.set_parent_scope(b.scope, *parent);
  } else {
    self.register_function_scope(b.scope);
  }

  let prev_scope = self.scope;
  self.scope = Some(b.scope);
  self.walk_block(b);
  self.scope = prev_scope;
}
\end{lstlisting}

Should the \texttt{Walker} encounter a declaration statement, it creates an entry in the local Block Scope \texttt{HashMap} mapping the identifier to its respective data type. And recursively resolves the rhs expression.

\begin{lstlisting}[language=C]
fn visit_statement(
  &mut self, 
  s: &mut Span<crate::ast::STATEMENT>
) {
  if let STATEMENT::Declaration { binding, expr } 
    = &mut **s {

    // register variable in local block scope
    self.symtbl.register_variable(
      self.scope.as_ref().unwrap(),
      &*binding
    );

    self.visit_expression(expr);
  }

  self.walk_statement(s);
}
\end{lstlisting}

Should the \texttt{Walker} encounter an expression, it determines whether the expression is a Call or a Variable. Should the expression be a variable, it uses the SymbolTable to determine whether the variable has been previously declared in the program before it was used. Else it throws an exception. Should it be a call, it determines whether the left hand side resolves to an identifier, and that that identifier corresponds to a predeclared function symbol.

\begin{lstlisting}[language=C]
fn visit_expression(
  &mut self, 
  e: &mut Span<crate::ast::EXPRESSION>
) {
  match &mut **e {
    // if the expression is a call, determine whether
    // the identifier corresponds to a declared subroutine

    EXPRESSION::Call { func, args } => {

      // ensure the LHS is an identifier 
      let ident = if let EXPRESSION::Variable { ident } 
        = &mut ***func {
        ident
      } else {
        fatal_at!("Attempt to call a non-function")
      };

      // ensure identifier corresponds to a declared symbol
      let symbol = if let Some(symbol) 
        = self.symtbl.lookup_symbol(ident) {
        symbol
      } else {
        fatal_at!("Attempt to call undeclared function")
      };

      // ensure the symbol is a function not a constant
      match symbol {
        SYMBOL::Function { .. } => {},
        _ => fatal_at!("Cannot call constant {ident}")
      }

      for arg in args.iter_mut() {
        self.visit_expression(arg);
      }

      // don't visit sub expressions
      return; 
    },
    
    // ensure the variable is declared before usage
    EXPRESSION::Variable { ident } => {
      self.symtbl.resolve_variable(
        self.scope.unwrap(), ident).unwrap_or_else(|| 
        fatal_at!(
          format!("use of undeclared identifier '{ident}'"),
      ));
    },

    _ => {},
  };

  self.walk_expression(e);
}
\end{lstlisting}

\subsubsection{Code Generation}
Code generation is performed in two steps, the first step generates an intermediate representation of the parsed abstract syntax tree - consisting of a list of \texttt{BLOCK}'s each corresponding to machine code instructions. The second step iterates through each \texttt{BLOCK} and generates the machine code for that particular block, inserting labels where required. Each block doesn't neccessarily represent one machine code instruction, for example, \texttt{BLT} will expand into a \texttt{SLT} and \texttt{BNE} instruction. 

\begin{lstlisting}[language=C]
#[derive(Debug, Clone)]
pub enum BLOCK {
  ADD(Register, Register, Register),
  SUB(Register, Register, Register),
  AND(Register, Register, Register),
  OR(Register, Register, Register),
  XOR(Register, Register, Register),

  ADDI(Register, Register, i16),

  EE(Register, Register, Register),
  NE(Register, Register, Register),
  LT(Register, Register, Register),
  GT(Register, Register, Register),
  LTE(Register, Register, Register),
  GTE(Register, Register, Register),

  NOR(Register, Register, Register),
  NOT(Register, Register),

  LABEL(Label),
  JAL(Register, Label),
  JMP(Label),
  JR(Register),
  HLT,

  BEQ(Register, Register, Label),
  BLT(Register, Register, Label),

  MOV(Register, Register),
  LI(Register, Number),
  LW(Register, Register, i16), // lw $rt, offset($rs)
  SW(Register, Register, i16), // sw rt, offset($rs)

  PUSH(Register),
  POP(Register),
}

#[derive(Debug, Clone)]
pub struct Number(pub u16);

#[derive(Debug, Clone)]
pub struct Label(pub String);

#[derive(Debug, Clone)]
pub struct Register(pub String); 
\end{lstlisting}

The IR struct (wrapping the IR generating code) has a current function context reference, symbol table reference, hashmap for used labels, and an output vector of \texttt{BLOCK}'s. Since the generator reuses labels (e.g. \texttt{.endif}) and each label has to be unique, the IR stores the number of times each label has been used. This is then appended onto the label to generate a unique instance. (e.g. \texttt{.endif-2}). 

The function context corresponds to the current stack frame the compiler is working under. This stores a return label, so any \texttt{return} instructions inside the function know where to exit the function. A current stack pointer pointing to the next free stack slot (offset from the base pointer), when anything is added onto the stack, it is stored in the memory location given by \texttt{stack\_pointer} and \texttt{stack\_pointer} is decremented (since the stack grows downwards). The function context also stores a reference to the block scope of the function, containing all local variables and their offsets from the base pointer. 

\begin{lstlisting}[language=C]
pub struct Ir<'a> {
  ir: Vec<BLOCK>,
  fctx: Option<Fctx>,
  symtbl: &'a mut SymbolTable,
  labels: HashMap<String, u16>,
}

#[derive(Debug)]
struct Fctx {
  l_ret: Label,

  // offset from $bp (grows downwards, 
  // thus negate when accessing memory)
  stack_pointer: i16, 
  scope: ScopeId,
}
\end{lstlisting}

This method takes in a parsed function node, with an identifier, set of parameter bindings, and body; and outputs the sequence of intermediate instructions used to represent this. It creates a new function context and prepends the function prologue, setting up the stack frame for that particular function. It then assigns each parameter a slot on the stack from which it can be referenced. It recursively calls \texttt{translate\_block()} to compile the function body, before inserting the function epiologue.

\label{translate_fn}
\begin{lstlisting}[language=C]
fn translate_fn(
  &mut self, 
  ident: &Span<Identifier>, 
  bindings: &Vec<Span<Binding>>, 
  body: &Span<Block>
) {
  self.fctx = Some(Fctx{
    stack_pointer: -1, // since 0 points to $bp
    l_ret: self.label("ret"),
    scope: body.scope,
  });

  // function prologue
  //   .[ident]
  //   push $ra 
  //   push $bp
  //   mov $bp, $sp
  self.ir.push(BLOCK::LABEL(Label(ident.ident.clone())));
  self.ir.push(BLOCK::PUSH(Register::from("$ra")));
  self.ir.push(BLOCK::PUSH(Register::from("$bp")));
  self.ir.push(BLOCK::MOV(
    Register::from("$bp"), 
    Register::from("$sp")
  ));


  // register each binding in the local stack frame
  for (i, binding) in bindings.iter().enumerate() {
    let scope = self.fctx().scope;

    // evaluate argument and push to stack 
    self.ir.push(BLOCK::LW(
      Register::from("$r0"), 
      Register::from("$bp"), 
      2 + i as i16)
    );

    self.push(Register::from("$r0"));

    let sp = self.fctx().stack_pointer + 1; 

    // register parameter stack slot 
    self.symtbl.set_slot(scope, &binding.ident, sp);
  }

  self.translate_block(body);

  // insert function epiologue
  //   .return
  //   mov $sp, $bp
  //   pop $bp
  //   pop $ra
  //   jr $ra
  let l_ret = self.fctx().l_ret.clone();

  self.ir.push(BLOCK::LABEL(l_ret));
  self.ir.push(BLOCK::MOV(
    Register::from("$sp"), 
    Register::from("$bp")
  ));

  self.ir.push(BLOCK::POP(Register::from("$bp")));
  self.ir.push(BLOCK::POP(Register::from("$ra")));
  self.ir.push(BLOCK::JR(Register::from("$ra")));
}
\end{lstlisting}

The following function translates an 'if' node. It evaluates the conditional expression first, jumping to the 'else' clause should the result be 0. The subsequent 'then' and 'else' statements can also be if nodes, meaning that if-elseif statements can be compiled recursively. 

\begin{lstlisting}[language=C]
fn translate_if(
  &mut self, 
  cond: &Span<EXPRESSION>, 
  conseq: &Span<Block>, 
  altern: &Option<Box<Span<Block>>>
) {
  let l_else = self.label("else");
  let l_end = self.label("endif");

  // condition == 0 => branch .else
  self.translate_expression(cond);
  self.ir.push(BLOCK::BEQ(
    Register::from("$r0"), 
    Register::from("$zero"), 
    l_else.clone()
  ));

  // [...then]
  self.translate_block(conseq);

  // jmp .end
  self.ir.push(BLOCK::JMP(l_end.clone()));

  // .else
  // [...else]
  self.ir.push(BLOCK::LABEL(l_else.clone()));
  if let Some(altern) = altern {
    self.translate_block(altern);
  }

  // .end
  self.ir.push(BLOCK::LABEL(l_end));
}
\end{lstlisting}

To translate a declaration statement, I first evaluate the result of the expression which is stored in register \texttt{\$r0}. I push this value onto the stack and make a note of its memory address, storing its offset from the base pointer in the function context symbol table, and decrementing the stack pointer accordingly to point to the next free slot.

\begin{lstlisting}[language=C]
fn translate_declaration(
  &mut self, 
  binding: &Span<Binding>, 
  expr: &Span<EXPRESSION>
) {
  // translate expression, store in $r0, 
  // push $r0 to the stack and record offset from $bp
  self.translate_expression(expr);

  // decrement stack pointer and store variable on stack
  let sp = self.fctx().stack_pointer;
  self.ir.push(BLOCK::ADDI(
    Register::from("$sp"), 
    Register::from("$sp"), 
    -1
  ));

  self.ir.push(BLOCK::SW(
    Register::from("$r0"), 
    Register::from("$bp"), 
    sp)
  );

  self.fctx().stack_pointer -= 1;

  let scope = self.fctx().scope;

  // update variables stack slot entry in symbol table
  self.symtbl.set_slot(scope, &binding.ident, sp);
}
\end{lstlisting}

To evaluate a variable, it will either be a constant or a local variable. The symbol table stores a HashMap mapping each constant to a value, so this can simply be subtituted in. For a variable, a record will exist in the function's context mapping that identifier to a stack slot. To resolve the variable from memory, I load the word at the memory location given by (\texttt{base pointer + stack slot}) into \texttt{\$r0}.

\begin{lstlisting}[language=C]
// LOAD $r0, stack_slot($bp) 
fn translate_variable(&mut self, ident: &Span<Identifier>) {
  let scope = self.fctx().scope;

  if let Some(stack_slot) = self.symtbl
    .resolve_variable(scope, ident)
    .expect("reference to undeclared variable")
    .stack_slot {

    // if a variable has been assigned a stack slot 
    // load from memory into $r0
    self.ir.push(BLOCK::LW(
      Register::from("$r0"), 
      Register::from("$bp"), 
      stack_slot)
    );

  } else if let Some(SYMBOL::Const { expr , ..}) = self.symtbl.lookup_symbol(ident){
    self.translate_expression(&expr);
  }
}
\end{lstlisting}

The following function evaluates any prefix expressions, namely dereferences and a pointers. To dereference a variable, the right hand side of the expression is evlauted, and whatever value in memory exists at that address is written into the register \texttt{\$r0}. A pointer however, resolves to the memory address of the variable you are referencing. The stack slot is looked up in the symbol table, and the memory address is calculated by adding that offset to the base pointer. \texttt{\$r0} is set to the result of this calculation. 

\begin{lstlisting}[language=C]
fn translate_prefix(
  &mut self, 
  op: &UNOP, 
  rhs: &Span<EXPRESSION>
) {
  match op {
    // evaluate the rhs (stores address of variable in $r0)
    // load word from the address in $r0
    UNOP::DEREF => {
      self.translate_expression(rhs);
      self.ir.push(BLOCK::LW(
        Register::from("$r0"), 
        Register::from("$r0"), 
        0
      ));
    },

    // PTR (load memory address of vairable into $r0)
    // memory address of variable is its offset from the 
    // base pointer + the address of the base pointer
    UNOP::PTR => {
      if let EXPRESSION::Variable { ident } = &**rhs {
          let scope = self.fctx().scope;
          let stack_slot = self.symtbl
            .resolve_variable(scope, ident)
            .stack_slot

          // stores mem addr of variable in $r0
          self.ir.push(BLOCK::ADDI(
            Register::from("$r0"), 
            Register::from("$bp"), 
            stack_slot
          ));

        } else if let EXPRESSION::Literal { lit } = &**rhs{
          self.translate_literal(lit);
        }
    },

    UNOP::NEG => {
      self.translate_expression(rhs);

      // to negate a value, subtract it from 0
      self.ir.push(BLOCK::SUB(
        Register::from("$r0"), 
        Register::from("$zero"),
        Register::from("$r0")
      ));
    },

    // [...]
  }
}
\end{lstlisting}

The following function translates any infix nodes. It recursively evaluates the lhs of the expression, pushing the result onto the stack. It then evaluates the rhs into \texttt{\$r0} and pops the lhs back into \texttt{\$r1}. The operation is then performed on those two registers. 

\begin{lstlisting}[language=C]
fn translate_infix(
  &mut self, 
  lhs: &Span<EXPRESSION>, 
  op: &BINOP, 
  rhs: &Span<EXPRESSION>
) {
  // evaluate lhs and store on the stack
  self.translate_expression(lhs);
  self.push(Register::from("$r0"));

  // evaluate rhs into $r0 and pop lhs back into $r1
  self.translate_expression(rhs);
  self.pop(Register::from("$r1"));

  // perform the operation on registers $r0 and $r1
  match op {
    BINOP::ADD => self.ir.push(BLOCK::ADD(
      Register::from("$r0"), 
      Register::from("$r1"), 
      Register::from("$r0")
    )),

    // [...] 

    BINOP::GTE => self.ir.push(BLOCK::GTE(
      Register::from("$r0"), 
      Register::from("$r1"), 
      Register::from("$r0")
    )),
  };
}
\end{lstlisting}

The call statement is responsible for preparing the arguments required to call a function, and in turn removing them from the stack once execution has completed. It evaluates and pushes each argument onto the stack in order (thus storing the arguments in the stack slots the function has pre-assigned for parameters). It then jumps to the address of the first instruction, storing the return address in \texttt{\$ra}. Finally, once the function has been executed, it decrements the stack pointer by the number of arguments, returning the stack to its initial state before the function was called. 

\begin{lstlisting}[language=C]
fn translate_call(
  &mut self, 
  func: &Span<EXPRESSION>, 
  args: &Vec<Span<EXPRESSION>>
) {
  // fetch the function identifier
  let ident = EXPRESSION::Variable { ident } = &**func 

  // evaluate and push each argument onto the stack 
  for arg in args.into_iter().rev() {
    self.translate_expression(arg);
    self.ir.push(BLOCK::PUSH(Register::from("$r0")));
  }

  // jump to the label given by the function identifier
  // store the return address in $ra
  self.ir.push(BLOCK::JAL(
    Register::from("$ra"), 
    Label(ident.ident.clone())
  ));

  // after function execution decrement $sp to pop 
  // arguments off of the stack and restore state
  self.ir.push(BLOCK::ADDI(
    Register::from("$sp"), 
    Register::from("$sp"), 
    args.len() as i16
  ));
}
\end{lstlisting}

There are two types of assignments this language supports: values can be assigned to local variables or to memory locations directly. To assign a value o a variable, the memory address is calculated from the base pointer and stack slot and the result of the expression is stored using a \texttt{sw} instruction. When assigning directly to a memory address, the lhs of the assignment is evaluated and the result of the expression is stored directly in that memory address. 

\begin{lstlisting}[language=C]
fn translate_assign(
  &mut self, 
  lhs: &Span<EXPRESSION>, 
  rhs: &Span<EXPRESSION>
) {
  // resolve address of variable:
  //   - STACK: lookup offset in the stack frame
  //   - DEREF: translate rhs, rhs is a pointer 
  //            thus holds the address to write to

  self.translate_expression(rhs);

  match &**lhs {
    EXPRESSION::Variable { ident }  => {
      let scope = self.fctx().scope;

      let stack_slot = self.symtbl
        .resolve_variable(scope, ident)
        .stack_slot;

      // store $r0 in address where addr = $bp + stack slot
      self.ir.push(BLOCK::SW(
        Register::from("$r0"), 
        Register::from("$bp"), 
        stack_slot
      ));
    },

    // assign to dereferenced memory address
    EXPRESSION::Prefix { op: UNOP::DEREF, rhs } => {
      // push variable memory address onto the stack 
      self.push(Register::from("$r0"));

      // evaluate expression and store in $r0
      self.translate_expression(rhs);

      // retrieve memory address from the stack
      self.pop(Register::from("$r1"));

      // store $r0 in the memory address in $r1
      self.ir.push(BLOCK::SW(
        Register::from("$r1"),
        Register::from("$r0"), 
        0
      ));
    }
  }
}
\end{lstlisting}

\subsection{Unit Testing}
Throughout the duration of the project, I have used unit testing to ensure the system works as intended. Below, I have included a sample of the unit tests used for the assembler's lexer, and the program's output.

\begin{lstlisting}
#[cfg(test)]
mod test {
  use super::*;
  #[test]
  fn test_lex_identifiers() {
    let mut lexer = Lexer::new("$a0 .label $a1\n.a$zero.1");
    let tokens = lexer.tokenize().unwrap();
    assert_eq!(
      tokens,
      vec![
        Span::new(Token::Register(1), Loc::new(0, 2)),
        Span::new(Token::Label(".label".to_string()), Loc::new(4, 9)),
        Span::new(Token::Register(2), Loc::new(11, 13)),
        Span::new(Token::NEWLINE, Loc::new(14, 14)),
        Span::new(Token::Label(".a".to_string()), Loc::new(15, 16)),
        Span::new(Token::Register(0), Loc::new(17, 21)),
        Span::new(Token::Label(".1".to_string()), Loc::new(22, 23)),
        Span::new(Token::EOF, Loc::new(24, 24)),
      ]
    )
  }

  #[test]
  fn test_lex_hexidecimal_numeral() {
    let mut lexer = Lexer::new("0xffff 0x00da\n0xf");
    let tokens = lexer.tokenize().unwrap();
    assert_eq!(
      tokens,
      vec![
        Span::new(Token::Number(65535), Loc::new(0, 5)),
        Span::new(Token::Number(218), Loc::new(7, 12)),
        Span::new(Token::NEWLINE, Loc::new(13, 13)),
        Span::new(Token::Number(15), Loc::new(14, 16)),
        Span::new(Token::EOF, Loc::new(17, 17)),
      ]
    )
  }

  #[test]
  fn test_error_unexpected_char() {
    let mut lexer = Lexer::new("mov %r4, $r0");
    assert_eq!(lexer.tokenize().is_err(), true);
  }
}
\end{lstlisting}

\begin{lstlisting}
> assembler git:(assembler) cargo test
Compiling assembler v0.1.0 (/Users/ldesilva/Documents/School/Computer Science/NEA/NEA-Code/assembler)
  Finished test [unoptimized + debuginfo] target(s) in 1.07s
  Running unittests src/main.rs (target/debug/deps/assembler-418adfb0c6d1f1d5)

running 18 tests
test exception::tests::test_error_on_first_line ... ok
test exception::tests::test_error_on_subsequent_lines ... ok
test lexer::test::test_error_overflow_binary_numeral ... ok
test lexer::test::test_error_overflow_denary_numeral ... ok
test lexer::test::test_error_overflow_hexadecimal_numeral ... ok
test lexer::test::test_error_unexpected_char ... ok
test lexer::test::test_error_unexpected_binary_numeral ... ok
test lexer::test::test_error_unexpected_hexidecimal_numeral ... ok
test lexer::test::test_lex_decimal_numeral ... ok
test lexer::test::test_lex_comments ... ok
test lexer::test::test_lex_hexidecimal_numeral ... ok
test lexer::test::test_error_unexpected_mneumonic ... ok
test parser::test::test_parse_rir ... ok
test lexer::test::test_lex_keywords ... ok
test parser::test::test_parse_rrr ... ok
test lexer::test::test_error_unexpected_denary_numeral ... ok
test parser::test::test_parse_rri ... ok
test lexer::test::test_lex_identifiers ... ok

test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s
\end{lstlisting}